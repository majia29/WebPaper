## 谷歌、阿里等10大深度学习CTR模型最全演化图谱

> 原创： 王喆 AI前线  
> 作者｜硅谷高级机器学习工程师 王喆  
> 编辑｜Vincent

随着微软的 Deep Crossing、Google 的 Wide&Deep 以及 FNN、PNN 等一大批优秀的深度学习 CTR 预估模型在 2016 年被提出，计算广告和推荐系统领域全面进入了深度学习时代，时至今日，深度学习 CTR 模型已经成为广告和推荐领域毫无疑问的主流。在之前的专栏文章  [《前深度学习时代 CTR 预估模型的演化之路》][1] 
中，我们与大家一起探讨了传统 CTR 模型的结构特点以及演化关系。在进入深度学习时代之后，CTR 模型不仅在表达能力、模型效果上有了质的提升，而且大量借鉴并融合了深度学习在图像、语音以及自然语言处理方向的成果，在模型结构上进行了快速的演化。

本文总结了广告、推荐领域最为流行的 10 个深度学习 CTR 模型的结构特点，构建了它们之间的演化图谱。选择模型的标准尽量遵循下面三个原则：
1. 模型的在业界影响力较大的；
2. 已经被 Google、微软、阿里等知名互联网公司成功应用的；
3. 工程导向的，而不是仅用实验数据验证或学术创新用的。

下面首先列出这张深度学习 CTR 模型的演化图谱，再对其进行逐一介绍：

![深度学习 CTR 模型演化图谱](https://majia29.github.io/mp2html/images/mp-20190419-ggald10d-01.png)  
图 1 深度学习 CTR 模型演化图谱

一、微软 Deep Crossing（2016 年）——深度学习 CTR 模型的 base model

![微软 Deep Crossing 模型架构图](https://majia29.github.io/mp2html/images/mp-20190419-ggald10d-02.png)  
图 2 微软 Deep Crossing 模型架构图

微软于 2016 年提出的 Deep Crossing 可以说是深度学习 CTR 模型的最典型和基础性的模型。如图 2 的模型结构图所示，它涵盖了深度 CTR 模型最典型的要素，即通过加入 embedding 层将稀疏特征转化为低维稠密特征，用 stacking layer，或者叫做 concat layer 将分段的特征向量连接起来，再通过多层神经网络完成特征的组合、转换，最终用 scoring layer 完成 CTR 的计算。

跟经典 DNN 有所不同的是，Deep crossing 采用的 multilayer perceptron 是由残差网络组成的，这无疑得益于 MSRA 著名研究员何恺明提出的著名的 152 层 ResNet。

二、FNN（2016 年）——用 FM 的隐向量完成 Embedding 初始化

![图 3 FNN 模型架构图](https://majia29.github.io/mp2html/images/mp-20190419-ggald10d-03.png)  
图 3 FNN 模型架构图

FNN 相比 Deep Crossing 的创新在于使用 FM 的隐层向量作为 user 和 item 的 Embedding，从而避免了完全从随机状态训练 Embedding。由于 id 类特征大量采用 one-hot 的编码方式，导致其维度极大，向量极稀疏，所以 Embedding 层与输入层的连接极多，梯度下降的效率很低，这大大增加了模型的训练时间和 Embedding 的不稳定性，使用 pre train 的方法完成 Embedding 层的训练，无疑是降低深度学习模型复杂度和训练不稳定性的有效工程经验。

三、PNN (2016 年)——丰富特征交叉的方式

![图 4 PNN 模型架构图](https://majia29.github.io/mp2html/images/mp-20190419-ggald10d-04.png)  
图 4 PNN 模型架构图





[1]: http://example.com/  "前深度学习时代 CTR 预估模型的演化之路"
